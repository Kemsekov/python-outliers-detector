{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from random import randint\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from common import get_full_data\n",
    "# load data\n",
    "def steel_strength():\n",
    "    df = pd.read_csv(\"dataset/steel_strength.csv\")\n",
    "    # get dependent and independent features\n",
    "    X=df.iloc[:,1:-3]\n",
    "    y=df.iloc[:,-2]\n",
    "    return get_full_data(X,y)\n",
    "\n",
    "def renewable():\n",
    "    df = pd.read_csv(\"dataset/Renewable.csv\")\n",
    "    time = df[\"Time\"].apply(lambda x: datetime.datetime.fromisoformat(x))\n",
    "    df=df.drop(columns=[\"Time\"])\n",
    "    df[\"month\"] = time.apply(lambda t: t.month)\n",
    "    df[\"day\"] = time.apply(lambda t: t.day)\n",
    "    df[\"hour\"] = time.apply(lambda t: t.hour)\n",
    "    df[\"minute\"] = time.apply(lambda t: t.minute)\n",
    "    return df.iloc[:,1:], df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "X,y = renewable()\n",
    "\n",
    "# for high-dimensional data use `gpu` for device if you have one\n",
    "special_model = XGBRegressor(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from render import *\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_small = pca.fit_transform(X)\n",
    "y_n = y.to_numpy()[:,np.newaxis]\n",
    "X_small=np.concatenate([X_small,np.ones_like(y_n),y_n],axis=1)\n",
    "print(sum(pca.explained_variance_ratio_))\n",
    "np.random.shuffle(X_small)\n",
    "plot_2d_rgb(X_small,\"original data\",[\"d1\",\"d2\",\"generated power\"], template=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from common import XGB_search_params\n",
    "\n",
    "params = XGB_search_params()\n",
    "state = randint(0,1000)\n",
    "search = RandomizedSearchCV(\n",
    "    special_model,\n",
    "    params,\n",
    "    n_iter=100,\n",
    "    cv=5,\n",
    "    random_state=state,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# amount of samples used for parameters search\n",
    "search_space_samples=5000\n",
    "\n",
    "if search_space_samples>=len(X):\n",
    "    search_space_samples=len(X)-1\n",
    "\n",
    "_,X_search,_,y_search = train_test_split(X,y,test_size=search_space_samples/len(X))\n",
    "\n",
    "search.fit(X_search,y_search)\n",
    "special_model=search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do repeated stratified k-fold cross-validation with classification report\n",
    "from sklearn.model_selection import RepeatedKFold, RepeatedStratifiedKFold, cross_val_score\n",
    "from common import cross_val_score_mean_std\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=50)\n",
    "r2_scoring = metrics.make_scorer(metrics.r2_score)\n",
    "print(\"r2 scoring\")\n",
    "cross_val_score_mean_std(cross_val_score(special_model,X,y,cv=cv,scoring=r2_scoring),y.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New method\n",
    "from common import find_outliers\n",
    "X_numpy = X.to_numpy()\n",
    "y_numpy = y.to_numpy()\n",
    "\n",
    "outliers_mask, score = find_outliers(\n",
    "    X_numpy,\n",
    "    y_numpy,\n",
    "    special_model,\n",
    "    outliers_to_remove=0.1,\n",
    "    iterations=5,\n",
    "    gamma=0.99,\n",
    "    evaluate_loss=metrics.mean_squared_error,\n",
    "    cv=5,\n",
    "    repeats=3,\n",
    "    plot=True\n",
    ")\n",
    "print(\"removed \",np.sum(outliers_mask)/len(y))\n",
    "X_clean = X_numpy[~outliers_mask]\n",
    "y_clean = y_numpy[~outliers_mask]\n",
    "\n",
    "r2_scoring = metrics.make_scorer(metrics.r2_score)\n",
    "print(\"r2 score\")\n",
    "cross_val_score_mean_std(cross_val_score(special_model,X_clean,y_clean,cv=cv,scoring=r2_scoring),y.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean = X_numpy[~outliers_mask]\n",
    "y_clean = y_numpy[~outliers_mask][:,np.newaxis]\n",
    "\n",
    "X_clean_small = pca.transform(X_clean)\n",
    "to_render=np.concatenate([X_clean_small,np.ones_like(y_clean),y_clean],axis=1)\n",
    "plot_2d_rgb(to_render,\"clean data\",[\"d1\",\"d2\",\"generated power\"],template=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score method\n",
    "from scipy import stats\n",
    "data = pd.concat([X,y],axis=1)\n",
    "z = np.abs(stats.zscore(data))\n",
    "threshold = 3\n",
    "data_clean = data[(z < threshold).all(axis=1)]\n",
    "\n",
    "X_clean=data_clean.iloc[:,:-2]\n",
    "y_clean=data_clean.iloc[:,-1]\n",
    "\n",
    "r2_scoring = metrics.make_scorer(metrics.r2_score)\n",
    "print(\"r2 score\")\n",
    "cross_val_score_mean_std(cross_val_score(special_model,X_clean,y_clean,cv=cv,scoring=r2_scoring),y.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is a Pandas DataFrame\n",
    "Q1 = data.quantile(0.05)\n",
    "Q3 = data.quantile(0.95)\n",
    "IQR = Q3 - Q1\n",
    "data_clean = data[~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "X_clean=data_clean.iloc[:,:-2]\n",
    "y_clean=data_clean.iloc[:,-1]\n",
    "\n",
    "r2_scoring = metrics.make_scorer(metrics.r2_score)\n",
    "cross_val_score_mean_std(cross_val_score(special_model,X_clean,y_clean,cv=cv,scoring=r2_scoring),y.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "clf = IsolationForest(random_state=50)\n",
    "outliers_pred=clf.fit_predict(data)\n",
    "\n",
    "data_clean = data[outliers_pred==1]\n",
    "\n",
    "X_clean=data_clean.iloc[:,:-2]\n",
    "y_clean=data_clean.iloc[:,-1]\n",
    "\n",
    "r2_scoring = metrics.make_scorer(metrics.r2_score)\n",
    "cross_val_score_mean_std(cross_val_score(special_model,X_clean,y_clean,cv=cv,scoring=r2_scoring),y.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare performance with some control model `KernelRidge` with `rbf` kernel and standard scaler\n",
    "\n",
    "do parameters search for it using `RandomSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
